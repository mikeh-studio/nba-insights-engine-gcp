{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e683f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeh/anaconda3/lib/python3.11/site-packages/pandas/core/computation/expressions.py:22: UserWarning: Pandas requires version '2.10.2' or newer of 'numexpr' (version '2.8.4' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/mikeh/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:56: UserWarning: Pandas requires version '1.4.2' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from typing import Iterable, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from nba_api.stats.endpoints import playergamelog\n",
    "from nba_api.stats.static import players\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "logger = logging.getLogger(\"nba_pipeline\")\n",
    "\n",
    "SEASON = os.getenv(\"NBA_SEASON\", \"2024-25\")\n",
    "RUN_FULL_EXTRACT = os.getenv(\"NBA_RUN_FULL_EXTRACT\", \"false\").lower() == \"true\"\n",
    "MAX_PLAYERS = int(os.getenv(\"NBA_MAX_PLAYERS\", \"25\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "znpvxzzvya",
   "metadata": {},
   "source": [
    "# NBA Analytics Pipeline\n",
    "\n",
    "An end-to-end data pipeline that fetches NBA player statistics, generates daily leaderboards, and stores data in Google Cloud Platform.\n",
    "\n",
    "**Pipeline Flow:**\n",
    "```\n",
    "NBA API → Pandas (extract/clean) → GCS (land) → BigQuery (warehouse + SQL analytics) → Claude AI Summary\n",
    "```\n",
    "\n",
    "**Technologies:** Python, NBA API, Google Cloud Storage, BigQuery, Claude API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k5eyniueum",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "Fetch player game logs from the NBA API. Includes rate limiting to avoid API throttling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044e6c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 530 active players\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>is_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1630173</td>\n",
       "      <td>Precious Achiuwa</td>\n",
       "      <td>Precious</td>\n",
       "      <td>Achiuwa</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203500</td>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>Steven</td>\n",
       "      <td>Adams</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1628389</td>\n",
       "      <td>Bam Adebayo</td>\n",
       "      <td>Bam</td>\n",
       "      <td>Adebayo</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1630534</td>\n",
       "      <td>Ochai Agbaji</td>\n",
       "      <td>Ochai</td>\n",
       "      <td>Agbaji</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1630583</td>\n",
       "      <td>Santi Aldama</td>\n",
       "      <td>Santi</td>\n",
       "      <td>Aldama</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1641725</td>\n",
       "      <td>Trey Alexander</td>\n",
       "      <td>Trey</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1629638</td>\n",
       "      <td>Nickeil Alexander-Walker</td>\n",
       "      <td>Nickeil</td>\n",
       "      <td>Alexander-Walker</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1628960</td>\n",
       "      <td>Grayson Allen</td>\n",
       "      <td>Grayson</td>\n",
       "      <td>Allen</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1628386</td>\n",
       "      <td>Jarrett Allen</td>\n",
       "      <td>Jarrett</td>\n",
       "      <td>Allen</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1630631</td>\n",
       "      <td>Jose Alvarado</td>\n",
       "      <td>Jose</td>\n",
       "      <td>Alvarado</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                 full_name first_name         last_name  is_active\n",
       "0  1630173          Precious Achiuwa   Precious           Achiuwa       True\n",
       "1   203500              Steven Adams     Steven             Adams       True\n",
       "2  1628389               Bam Adebayo        Bam           Adebayo       True\n",
       "3  1630534              Ochai Agbaji      Ochai            Agbaji       True\n",
       "4  1630583              Santi Aldama      Santi            Aldama       True\n",
       "5  1641725            Trey Alexander       Trey         Alexander       True\n",
       "6  1629638  Nickeil Alexander-Walker    Nickeil  Alexander-Walker       True\n",
       "7  1628960             Grayson Allen    Grayson             Allen       True\n",
       "8  1628386             Jarrett Allen    Jarrett             Allen       True\n",
       "9  1630631             Jose Alvarado       Jose          Alvarado       True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all active NBA players\n",
    "active_players = players.get_active_players()\n",
    "players_df = pd.DataFrame(active_players)\n",
    "\n",
    "selected_players = active_players if RUN_FULL_EXTRACT else active_players[:MAX_PLAYERS]\n",
    "logger.info(\"Found %s active players\", len(players_df))\n",
    "logger.info(\"Processing %s players for season %s\", len(selected_players), SEASON)\n",
    "\n",
    "players_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54bf2a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player: LeBron James, ID: 2544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>WL</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apr 11, 2025</td>\n",
       "      <td>LAL vs. HOU</td>\n",
       "      <td>W</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apr 09, 2025</td>\n",
       "      <td>LAL @ DAL</td>\n",
       "      <td>W</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr 08, 2025</td>\n",
       "      <td>LAL @ OKC</td>\n",
       "      <td>L</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr 06, 2025</td>\n",
       "      <td>LAL @ OKC</td>\n",
       "      <td>W</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apr 04, 2025</td>\n",
       "      <td>LAL vs. NOP</td>\n",
       "      <td>W</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apr 03, 2025</td>\n",
       "      <td>LAL vs. GSW</td>\n",
       "      <td>L</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mar 31, 2025</td>\n",
       "      <td>LAL vs. HOU</td>\n",
       "      <td>W</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mar 29, 2025</td>\n",
       "      <td>LAL @ MEM</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mar 27, 2025</td>\n",
       "      <td>LAL @ CHI</td>\n",
       "      <td>L</td>\n",
       "      <td>39</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mar 26, 2025</td>\n",
       "      <td>LAL @ IND</td>\n",
       "      <td>W</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GAME_DATE      MATCHUP WL  MIN  PTS  REB  AST  STL  BLK  TOV\n",
       "0  Apr 11, 2025  LAL vs. HOU  W   22   14    4    8    1    0    1\n",
       "1  Apr 09, 2025    LAL @ DAL  W   36   27    7    3    1    0    2\n",
       "2  Apr 08, 2025    LAL @ OKC  L   35   28    7    3    1    0    6\n",
       "3  Apr 06, 2025    LAL @ OKC  W   34   19    3    7    1    0    2\n",
       "4  Apr 04, 2025  LAL vs. NOP  W   33   27    0    8    2    0    1\n",
       "5  Apr 03, 2025  LAL vs. GSW  L   40   33    5    9    1    1    4\n",
       "6  Mar 31, 2025  LAL vs. HOU  W   38   16    8    4    2    2    3\n",
       "7  Mar 29, 2025    LAL @ MEM  W   37   25    6    8    3    1    3\n",
       "8  Mar 27, 2025    LAL @ CHI  L   39   17    5   12    2    0    4\n",
       "9  Mar 26, 2025    LAL @ IND  W   38   13   13    7    1    0    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to get game log for a player\n",
    "\n",
    "def get_player_game_log(player_id: int, season: str = SEASON, retries: int = 3, delay: float = 0.8) -> pd.DataFrame:\n",
    "    \"\"\"Get normalized game logs for a player with retry logic.\"\"\"\n",
    "    cols = [\"GAME_DATE\", \"MATCHUP\", \"WL\", \"MIN\", \"PTS\", \"REB\", \"AST\", \"STL\", \"BLK\", \"TOV\"]\n",
    "\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            gamelog = playergamelog.PlayerGameLog(player_id=player_id, season=season)\n",
    "            df = gamelog.get_data_frames()[0]\n",
    "\n",
    "            missing_cols = [c for c in cols if c not in df.columns]\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing expected columns: {missing_cols}\")\n",
    "\n",
    "            out = df[cols].copy()\n",
    "            out[\"GAME_DATE\"] = pd.to_datetime(out[\"GAME_DATE\"], errors=\"coerce\")\n",
    "            out = out.dropna(subset=[\"GAME_DATE\"])\n",
    "\n",
    "            numeric_cols = [\"MIN\", \"PTS\", \"REB\", \"AST\", \"STL\", \"BLK\", \"TOV\"]\n",
    "            for col in numeric_cols:\n",
    "                out[col] = pd.to_numeric(out[col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "            out[\"SEASON\"] = season\n",
    "            out[\"INGESTED_AT_UTC\"] = pd.Timestamp.utcnow()\n",
    "            return out\n",
    "        except Exception:\n",
    "            if attempt == retries:\n",
    "                logger.exception(\"Failed player_id=%s after %s attempts\", player_id, retries)\n",
    "                return pd.DataFrame()\n",
    "            sleep_seconds = delay * attempt\n",
    "            logger.warning(\"Retrying player_id=%s attempt=%s/%s in %.1fs\", player_id, attempt, retries, sleep_seconds)\n",
    "            time.sleep(sleep_seconds)\n",
    "\n",
    "    return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c54d2c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 1/5: Precious Achiuwa\n",
      "Fetching 2/5: Steven Adams\n",
      "Fetching 3/5: Bam Adebayo\n",
      "Fetching 4/5: Ochai Agbaji\n",
      "Fetching 5/5: Santi Aldama\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>WL</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apr 13, 2025</td>\n",
       "      <td>NYK @ BKN</td>\n",
       "      <td>W</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1630173</td>\n",
       "      <td>Precious Achiuwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apr 11, 2025</td>\n",
       "      <td>NYK vs. CLE</td>\n",
       "      <td>L</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1630173</td>\n",
       "      <td>Precious Achiuwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr 10, 2025</td>\n",
       "      <td>NYK @ DET</td>\n",
       "      <td>L</td>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1630173</td>\n",
       "      <td>Precious Achiuwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr 05, 2025</td>\n",
       "      <td>NYK @ ATL</td>\n",
       "      <td>W</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1630173</td>\n",
       "      <td>Precious Achiuwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apr 02, 2025</td>\n",
       "      <td>NYK @ CLE</td>\n",
       "      <td>L</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1630173</td>\n",
       "      <td>Precious Achiuwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Oct 30, 2024</td>\n",
       "      <td>MEM vs. BKN</td>\n",
       "      <td>L</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1630583</td>\n",
       "      <td>Santi Aldama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Oct 28, 2024</td>\n",
       "      <td>MEM vs. CHI</td>\n",
       "      <td>L</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1630583</td>\n",
       "      <td>Santi Aldama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Oct 26, 2024</td>\n",
       "      <td>MEM vs. ORL</td>\n",
       "      <td>W</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1630583</td>\n",
       "      <td>Santi Aldama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Oct 25, 2024</td>\n",
       "      <td>MEM @ HOU</td>\n",
       "      <td>L</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1630583</td>\n",
       "      <td>Santi Aldama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Oct 23, 2024</td>\n",
       "      <td>MEM @ UTA</td>\n",
       "      <td>W</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1630583</td>\n",
       "      <td>Santi Aldama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        GAME_DATE      MATCHUP WL  MIN  PTS  REB  AST  STL  BLK  TOV  \\\n",
       "0    Apr 13, 2025    NYK @ BKN  W   33   18    9    2    2    0    2   \n",
       "1    Apr 11, 2025  NYK vs. CLE  L   15    0    6    0    2    1    1   \n",
       "2    Apr 10, 2025    NYK @ DET  L   40   18   10    3    2    3    0   \n",
       "3    Apr 05, 2025    NYK @ ATL  W   25    6    3    0    0    2    1   \n",
       "4    Apr 02, 2025    NYK @ CLE  L   21   13    6    1    1    2    0   \n",
       "..            ...          ... ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "317  Oct 30, 2024  MEM vs. BKN  L   22    2    3    0    2    0    1   \n",
       "318  Oct 28, 2024  MEM vs. CHI  L   35   11   13    7    0    1    1   \n",
       "319  Oct 26, 2024  MEM vs. ORL  W   28   22    7    5    0    1    2   \n",
       "320  Oct 25, 2024    MEM @ HOU  L   22    2    5    3    0    2    2   \n",
       "321  Oct 23, 2024    MEM @ UTA  W   31   27    5    2    0    0    2   \n",
       "\n",
       "     PLAYER_ID       PLAYER_NAME  \n",
       "0      1630173  Precious Achiuwa  \n",
       "1      1630173  Precious Achiuwa  \n",
       "2      1630173  Precious Achiuwa  \n",
       "3      1630173  Precious Achiuwa  \n",
       "4      1630173  Precious Achiuwa  \n",
       "..         ...               ...  \n",
       "317    1630583      Santi Aldama  \n",
       "318    1630583      Santi Aldama  \n",
       "319    1630583      Santi Aldama  \n",
       "320    1630583      Santi Aldama  \n",
       "321    1630583      Santi Aldama  \n",
       "\n",
       "[322 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get game logs for multiple players (with rate limiting)\n",
    "def get_all_player_game_logs(player_list: Iterable[dict], season: str = SEASON, delay: float = 0.6) -> pd.DataFrame:\n",
    "    \"\"\"Fetch game logs for multiple players with basic resilience controls.\"\"\"\n",
    "    all_logs = []\n",
    "    player_list = list(player_list)\n",
    "\n",
    "    for i, player in enumerate(player_list, start=1):\n",
    "        player_id = player[\"id\"]\n",
    "        player_name = player[\"full_name\"]\n",
    "        logger.info(\"Fetching %s/%s: %s\", i, len(player_list), player_name)\n",
    "\n",
    "        games = get_player_game_log(player_id, season=season)\n",
    "        if not games.empty:\n",
    "            games[\"PLAYER_ID\"] = player_id\n",
    "            games[\"PLAYER_NAME\"] = player_name\n",
    "            all_logs.append(games)\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    if not all_logs:\n",
    "        raise RuntimeError(\"No game logs were fetched. Check API availability and season value.\")\n",
    "\n",
    "    all_game_logs = pd.concat(all_logs, ignore_index=True)\n",
    "    all_game_logs = all_game_logs.drop_duplicates(subset=[\"PLAYER_ID\", \"GAME_DATE\", \"MATCHUP\"]).copy()\n",
    "    all_game_logs = all_game_logs.sort_values([\"GAME_DATE\", \"PLAYER_ID\"], ascending=[False, True])\n",
    "\n",
    "    required = {\"GAME_DATE\", \"PLAYER_ID\", \"PLAYER_NAME\", \"PTS\", \"REB\", \"AST\"}\n",
    "    missing = required - set(all_game_logs.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required fields in merged logs: {sorted(missing)}\")\n",
    "\n",
    "    logger.info(\"Fetched %s rows across %s players\", len(all_game_logs), all_game_logs[\"PLAYER_ID\"].nunique())\n",
    "    return all_game_logs.reset_index(drop=True)\n",
    "\n",
    "\n",
    "all_game_logs = get_all_player_game_logs(selected_players)\n",
    "all_game_logs.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pymo9mwqo9h",
   "metadata": {},
   "source": [
    "## 2. Google Cloud Setup\n",
    "\n",
    "Configure Google Cloud Storage for data persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery, storage\n",
    "\n",
    "# Required runtime config\n",
    "PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\")\n",
    "BUCKET_NAME = os.getenv(\"GCS_BUCKET_NAME\")\n",
    "BQ_DATASET = os.getenv(\"BQ_DATASET\", \"nba_data\")\n",
    "BQ_LOCATION = os.getenv(\"BQ_LOCATION\", \"US\")\n",
    "\n",
    "missing_cfg = [name for name, value in {\n",
    "    \"GCP_PROJECT_ID\": PROJECT_ID,\n",
    "    \"GCS_BUCKET_NAME\": BUCKET_NAME,\n",
    "}.items() if not value]\n",
    "\n",
    "if missing_cfg:\n",
    "    raise EnvironmentError(f\"Missing required environment variables: {', '.join(missing_cfg)}\")\n",
    "\n",
    "logger.info(\"Configured PROJECT_ID=%s BUCKET_NAME=%s DATASET=%s\", PROJECT_ID, BUCKET_NAME, BQ_DATASET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mnjcgqcjck",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeh/anaconda3/lib/python3.11/site-packages/google/auth/_default.py:108: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket nba-data-485505 already exists\n"
     ]
    }
   ],
   "source": [
    "# Create bucket if it doesn't exist\n",
    "client = storage.Client(project=PROJECT_ID)\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "\n",
    "if bucket.exists(client):\n",
    "    logger.info(\"Bucket %s already exists\", BUCKET_NAME)\n",
    "else:\n",
    "    bucket = client.create_bucket(BUCKET_NAME, location=BQ_LOCATION.lower())\n",
    "    logger.info(\"Created bucket %s\", BUCKET_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de562587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload DataFrame to GCS\n",
    "def upload_df_to_gcs(df: pd.DataFrame, project_id: str, bucket_name: str, destination_blob_name: str) -> str:\n",
    "    \"\"\"Upload a DataFrame as CSV to Google Cloud Storage and return gs:// URI.\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"Refusing to upload empty DataFrame to {destination_blob_name}\")\n",
    "\n",
    "    gcs_client = storage.Client(project=project_id)\n",
    "    bucket = gcs_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    csv_data = df.to_csv(index=False)\n",
    "    blob.upload_from_string(csv_data, content_type=\"text/csv\")\n",
    "    uri = f\"gs://{bucket_name}/{destination_blob_name}\"\n",
    "    logger.info(\"Uploaded %s rows to %s\", len(df), uri)\n",
    "    return uri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cnoe7ibtad",
   "metadata": {},
   "source": [
    "## 3. Analytics - Daily Leaderboards\n",
    "\n",
    "Generate daily leaderboards for Points, Rebounds, and Assists. Also calculate season averages (PPG, RPG, APG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf67531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Leaderboards: Points, Rebounds, Assists\n",
    "\n",
    "def get_daily_leaderboard(df: pd.DataFrame, stat_column: str) -> pd.DataFrame:\n",
    "    \"\"\"Get deterministic daily leader per stat with date-safe sorting.\"\"\"\n",
    "    required_cols = {\"GAME_DATE\", \"PLAYER_NAME\", stat_column}\n",
    "    missing = required_cols - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns for leaderboard: {sorted(missing)}\")\n",
    "\n",
    "    working = df.copy()\n",
    "    working[\"GAME_DATE\"] = pd.to_datetime(working[\"GAME_DATE\"], errors=\"coerce\")\n",
    "    working = working.dropna(subset=[\"GAME_DATE\"])\n",
    "    working[stat_column] = pd.to_numeric(working[stat_column], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    leaders = (\n",
    "        working.sort_values([\"GAME_DATE\", stat_column, \"PLAYER_NAME\"], ascending=[False, False, True])\n",
    "        .drop_duplicates(subset=[\"GAME_DATE\"], keep=\"first\")\n",
    "        [[\"GAME_DATE\", \"PLAYER_NAME\", stat_column]]\n",
    "        .rename(columns={\"GAME_DATE\": \"Date\", \"PLAYER_NAME\": \"Player\"})\n",
    "        .sort_values(\"Date\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return leaders\n",
    "\n",
    "\n",
    "pts_leaders = get_daily_leaderboard(all_game_logs, \"PTS\")\n",
    "reb_leaders = get_daily_leaderboard(all_game_logs, \"REB\")\n",
    "ast_leaders = get_daily_leaderboard(all_game_logs, \"AST\")\n",
    "\n",
    "print(\"=== POINTS LEADERS BY DAY ===\")\n",
    "display(pts_leaders.head(10))\n",
    "\n",
    "print(\"\\n=== REBOUNDS LEADERS BY DAY ===\")\n",
    "display(reb_leaders.head(10))\n",
    "\n",
    "print(\"\\n=== ASSISTS LEADERS BY DAY ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h2uwazax7wt",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ast_leaders.head(10))\n",
    "\n",
    "# Combined view: All leaders side by side for each day\n",
    "combined = pts_leaders.merge(reb_leaders, on=\"Date\", suffixes=(\"_pts\", \"_reb\"))\n",
    "combined = combined.merge(ast_leaders, on=\"Date\")\n",
    "combined.columns = [\"Date\", \"PTS Leader\", \"PTS\", \"REB Leader\", \"REB\", \"AST Leader\", \"AST\"]\n",
    "combined[\"Date\"] = pd.to_datetime(combined[\"Date\"]).dt.date\n",
    "combined = combined.sort_values(\"Date\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== COMBINED DAILY LEADERBOARD ===\")\n",
    "combined.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fi50pd224rk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Season totals leaderboard\n",
    "season_totals = (\n",
    "    all_game_logs.groupby([\"PLAYER_ID\", \"PLAYER_NAME\"], as_index=False)\n",
    "    .agg({\"PTS\": \"sum\", \"REB\": \"sum\", \"AST\": \"sum\", \"GAME_DATE\": \"count\"})\n",
    "    .rename(columns={\"GAME_DATE\": \"GP\"})\n",
    ")\n",
    "\n",
    "season_totals[\"PPG\"] = (season_totals[\"PTS\"] / season_totals[\"GP\"]).round(1)\n",
    "season_totals[\"RPG\"] = (season_totals[\"REB\"] / season_totals[\"GP\"]).round(1)\n",
    "season_totals[\"APG\"] = (season_totals[\"AST\"] / season_totals[\"GP\"]).round(1)\n",
    "\n",
    "eligible = season_totals[season_totals[\"GP\"] >= 5].copy()\n",
    "if eligible.empty:\n",
    "    eligible = season_totals.copy()\n",
    "\n",
    "print(\"=== SEASON LEADERS (Per Game Averages, GP>=5 when available) ===\")\n",
    "print(f\"\\nPPG Leader: {eligible.loc[eligible['PPG'].idxmax(), 'PLAYER_NAME']} - {eligible['PPG'].max()}\")\n",
    "print(f\"RPG Leader: {eligible.loc[eligible['RPG'].idxmax(), 'PLAYER_NAME']} - {eligible['RPG'].max()}\")\n",
    "print(f\"APG Leader: {eligible.loc[eligible['APG'].idxmax(), 'PLAYER_NAME']} - {eligible['APG'].max()}\")\n",
    "\n",
    "print(\"\\n=== FULL SEASON STATS ===\")\n",
    "season_totals.sort_values([\"PPG\", \"RPG\", \"APG\"], ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "glf1512qe2j",
   "metadata": {},
   "source": [
    "## 4. Upload to Cloud Storage\n",
    "\n",
    "Export raw game logs and leaderboard data to Google Cloud Storage as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fl959hxfk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload raw game logs to GCS for BigQuery\n",
    "run_stamp = pd.Timestamp.utcnow().strftime(\"%Y%m%d\")\n",
    "game_logs_blob = f\"nba_data/{SEASON}/{run_stamp}/game_logs.csv\"\n",
    "game_logs_uri = upload_df_to_gcs(all_game_logs, PROJECT_ID, BUCKET_NAME, game_logs_blob)\n",
    "\n",
    "print(\"\\nRaw game logs uploaded to GCS!\")\n",
    "print(game_logs_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ixukk6o3v",
   "metadata": {},
   "source": [
    "## 5. BigQuery Integration\n",
    "\n",
    "Load raw game logs into BigQuery with **date partitioning** and **player clustering** for cost-optimized queries.\n",
    "Then perform analytics entirely in SQL: window functions, CTEs, conditional aggregation, and reusable views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xasdz20ad4l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BigQuery client\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Create dataset if it doesn't exist\n",
    "dataset_id = f\"{PROJECT_ID}.{BQ_DATASET}\"\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = BQ_LOCATION\n",
    "bq_client.create_dataset(dataset, exists_ok=True)\n",
    "\n",
    "RAW_STAGING_TABLE = f\"{PROJECT_ID}.{BQ_DATASET}.stg_game_logs\"\n",
    "RAW_GAME_LOGS_TABLE = f\"{PROJECT_ID}.{BQ_DATASET}.raw_game_logs\"\n",
    "GAME_LOGS_TABLE = RAW_GAME_LOGS_TABLE\n",
    "\n",
    "logger.info(\"Dataset ready: %s\", dataset_id)\n",
    "logger.info(\"Staging table: %s\", RAW_STAGING_TABLE)\n",
    "logger.info(\"Raw table: %s\", RAW_GAME_LOGS_TABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kuf7lbkmr1n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV from GCS to BigQuery with optional partitioning and clustering\n",
    "def load_gcs_to_bigquery(\n",
    "    gcs_uri: str,\n",
    "    table_id: str,\n",
    "    schema: List[bigquery.SchemaField],\n",
    "    partition_field: Optional[str] = None,\n",
    "    clustering_fields: Optional[List[str]] = None,\n",
    "    write_disposition: str = bigquery.WriteDisposition.WRITE_APPEND,\n",
    ") -> None:\n",
    "    \"\"\"Load a CSV from GCS into BigQuery with optional partitioning and clustering.\"\"\"\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        skip_leading_rows=1,\n",
    "        schema=schema,\n",
    "        write_disposition=write_disposition,\n",
    "    )\n",
    "\n",
    "    if partition_field:\n",
    "        job_config.time_partitioning = bigquery.TimePartitioning(\n",
    "            type_=bigquery.TimePartitioningType.DAY,\n",
    "            field=partition_field,\n",
    "        )\n",
    "    if clustering_fields:\n",
    "        job_config.clustering_fields = clustering_fields\n",
    "\n",
    "    load_job = bq_client.load_table_from_uri(gcs_uri, table_id, job_config=job_config)\n",
    "    load_job.result()\n",
    "\n",
    "    table = bq_client.get_table(table_id)\n",
    "    logger.info(\n",
    "        \"Loaded %s rows to %s (write=%s, partitioned=%s, clustered=%s)\",\n",
    "        table.num_rows,\n",
    "        table_id,\n",
    "        write_disposition,\n",
    "        partition_field or \"none\",\n",
    "        clustering_fields or \"none\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yuj8xl9z9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load incoming game logs into staging table\n",
    "game_logs_schema = [\n",
    "    bigquery.SchemaField(\"GAME_DATE\", \"DATE\"),\n",
    "    bigquery.SchemaField(\"MATCHUP\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"WL\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"MIN\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"PTS\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"REB\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"AST\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"STL\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"BLK\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"TOV\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"SEASON\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"INGESTED_AT_UTC\", \"TIMESTAMP\"),\n",
    "    bigquery.SchemaField(\"PLAYER_ID\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"PLAYER_NAME\", \"STRING\"),\n",
    "]\n",
    "\n",
    "load_gcs_to_bigquery(\n",
    "    game_logs_uri,\n",
    "    RAW_STAGING_TABLE,\n",
    "    game_logs_schema,\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded incoming file to staging table: {RAW_STAGING_TABLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality checks + MERGE from staging into partitioned raw table\n",
    "\n",
    "dq_query = f\"\"\"\n",
    "WITH base AS (\n",
    "  SELECT *\n",
    "  FROM `{RAW_STAGING_TABLE}`\n",
    "),\n",
    "dups AS (\n",
    "  SELECT COUNT(*) AS duplicate_keys\n",
    "  FROM (\n",
    "    SELECT player_id, game_date, matchup, COUNT(*) AS cnt\n",
    "    FROM base\n",
    "    GROUP BY player_id, game_date, matchup\n",
    "    HAVING COUNT(*) > 1\n",
    "  )\n",
    ")\n",
    "SELECT\n",
    "  (SELECT COUNT(*) FROM base) AS total_rows,\n",
    "  (SELECT COUNT(*) FROM base WHERE player_id IS NULL OR game_date IS NULL OR matchup IS NULL) AS null_key_rows,\n",
    "  (SELECT duplicate_keys FROM dups) AS duplicate_key_rows\n",
    "\"\"\"\n",
    "\n",
    "dq = bq_client.query(dq_query).to_dataframe().iloc[0].to_dict()\n",
    "print(\"=== DATA QUALITY CHECKS (staging) ===\")\n",
    "print(dq)\n",
    "\n",
    "if dq[\"total_rows\"] == 0:\n",
    "    raise ValueError(\"DQ failed: staging table has zero rows\")\n",
    "if dq[\"null_key_rows\"] > 0:\n",
    "    raise ValueError(f\"DQ failed: found {dq['null_key_rows']} rows with null business keys\")\n",
    "if dq[\"duplicate_key_rows\"] > 0:\n",
    "    raise ValueError(f\"DQ failed: found {dq['duplicate_key_rows']} duplicate business keys\")\n",
    "\n",
    "create_raw_table_ddl = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS `{RAW_GAME_LOGS_TABLE}` (\n",
    "  game_date DATE,\n",
    "  matchup STRING,\n",
    "  wl STRING,\n",
    "  min FLOAT64,\n",
    "  pts INT64,\n",
    "  reb INT64,\n",
    "  ast INT64,\n",
    "  stl INT64,\n",
    "  blk INT64,\n",
    "  tov INT64,\n",
    "  season STRING,\n",
    "  ingested_at_utc TIMESTAMP,\n",
    "  player_id INT64,\n",
    "  player_name STRING\n",
    ")\n",
    "PARTITION BY game_date\n",
    "CLUSTER BY player_id, player_name\n",
    "\"\"\"\n",
    "\n",
    "merge_sql = f\"\"\"\n",
    "MERGE `{RAW_GAME_LOGS_TABLE}` T\n",
    "USING `{RAW_STAGING_TABLE}` S\n",
    "ON T.player_id = S.player_id\n",
    "AND T.game_date = S.game_date\n",
    "AND T.matchup = S.matchup\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (game_date, matchup, wl, min, pts, reb, ast, stl, blk, tov, season, ingested_at_utc, player_id, player_name)\n",
    "  VALUES (S.game_date, S.matchup, S.wl, S.min, S.pts, S.reb, S.ast, S.stl, S.blk, S.tov, S.season, S.ingested_at_utc, S.player_id, S.player_name)\n",
    "\"\"\"\n",
    "\n",
    "bq_client.query(create_raw_table_ddl).result()\n",
    "pre_count = bq_client.query(f\"SELECT COUNT(*) AS c FROM `{RAW_GAME_LOGS_TABLE}`\").to_dataframe().iloc[0][\"c\"]\n",
    "bq_client.query(merge_sql).result()\n",
    "post_count = bq_client.query(f\"SELECT COUNT(*) AS c FROM `{RAW_GAME_LOGS_TABLE}`\").to_dataframe().iloc[0][\"c\"]\n",
    "\n",
    "print(\"\\nMERGE completed\")\n",
    "print(f\"Rows before merge: {pre_count}\")\n",
    "print(f\"Rows after merge:  {post_count}\")\n",
    "print(f\"Rows inserted:     {post_count - pre_count}\")\n",
    "print(f\"Partitioned by: game_date | Clustered by: player_id, player_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k1uccwv55ss",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily leaderboard using ROW_NUMBER() window function\n",
    "daily_leaders_query = f\"\"\"\n",
    "WITH ranked AS (\n",
    "  SELECT\n",
    "    game_date,\n",
    "    player_name,\n",
    "    pts, reb, ast,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY game_date ORDER BY pts DESC, player_name\n",
    "    ) AS pts_rank,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY game_date ORDER BY reb DESC, player_name\n",
    "    ) AS reb_rank,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY game_date ORDER BY ast DESC, player_name\n",
    "    ) AS ast_rank\n",
    "  FROM `{GAME_LOGS_TABLE}`\n",
    ")\n",
    "SELECT\n",
    "  p.game_date,\n",
    "  p.player_name AS pts_leader, p.pts,\n",
    "  r.player_name AS reb_leader, r.reb,\n",
    "  a.player_name AS ast_leader, a.ast\n",
    "FROM ranked p\n",
    "JOIN ranked r ON p.game_date = r.game_date AND r.reb_rank = 1\n",
    "JOIN ranked a ON p.game_date = a.game_date AND a.ast_rank = 1\n",
    "WHERE p.pts_rank = 1\n",
    "ORDER BY p.game_date DESC\n",
    "LIMIT 15\n",
    "\"\"\"\n",
    "\n",
    "results = bq_client.query(daily_leaders_query).to_dataframe()\n",
    "print(\"=== Daily Leaders (BigQuery window function: ROW_NUMBER) ===\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lu0ziaqnnu7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Season averages using GROUP BY with HAVING filter\n",
    "season_avg_query = f\"\"\"\n",
    "SELECT\n",
    "  player_name,\n",
    "  COUNT(*) AS gp,\n",
    "  SUM(pts) AS total_pts,\n",
    "  SUM(reb) AS total_reb,\n",
    "  SUM(ast) AS total_ast,\n",
    "  ROUND(AVG(pts), 1) AS ppg,\n",
    "  ROUND(AVG(reb), 1) AS rpg,\n",
    "  ROUND(AVG(ast), 1) AS apg,\n",
    "  ROUND(AVG(stl), 1) AS spg,\n",
    "  ROUND(AVG(blk), 1) AS bpg\n",
    "FROM `{GAME_LOGS_TABLE}`\n",
    "GROUP BY player_name\n",
    "HAVING COUNT(*) >= 5\n",
    "ORDER BY ppg DESC\n",
    "\"\"\"\n",
    "\n",
    "season_avg_df = bq_client.query(season_avg_query).to_dataframe()\n",
    "print(\"=== Season Averages (BigQuery GROUP BY + HAVING) ===\")\n",
    "season_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077utbhbtp1k",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reusable view for the daily leaderboard\n",
    "view_ddl = f\"\"\"\n",
    "CREATE OR REPLACE VIEW `{PROJECT_ID}.{BQ_DATASET}.v_daily_leaderboard` AS\n",
    "WITH ranked AS (\n",
    "  SELECT\n",
    "    game_date,\n",
    "    player_name,\n",
    "    pts, reb, ast,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY game_date ORDER BY pts DESC, player_name\n",
    "    ) AS pts_rank,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY game_date ORDER BY reb DESC, player_name\n",
    "    ) AS reb_rank,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY game_date ORDER BY ast DESC, player_name\n",
    "    ) AS ast_rank\n",
    "  FROM `{GAME_LOGS_TABLE}`\n",
    ")\n",
    "SELECT\n",
    "  p.game_date,\n",
    "  p.player_name AS pts_leader, p.pts,\n",
    "  r.player_name AS reb_leader, r.reb,\n",
    "  a.player_name AS ast_leader, a.ast\n",
    "FROM ranked p\n",
    "JOIN ranked r ON p.game_date = r.game_date AND r.reb_rank = 1\n",
    "JOIN ranked a ON p.game_date = a.game_date AND a.ast_rank = 1\n",
    "WHERE p.pts_rank = 1\n",
    "\"\"\"\n",
    "\n",
    "bq_client.query(view_ddl).result()\n",
    "logger.info(\"Created view: %s.%s.v_daily_leaderboard\", PROJECT_ID, BQ_DATASET)\n",
    "\n",
    "# Verify the view works\n",
    "view_df = bq_client.query(f\"\"\"\n",
    "SELECT * FROM `{PROJECT_ID}.{BQ_DATASET}.v_daily_leaderboard`\n",
    "ORDER BY game_date DESC\n",
    "LIMIT 5\n",
    "\"\"\").to_dataframe()\n",
    "\n",
    "print(\"=== View: v_daily_leaderboard (sample) ===\")\n",
    "view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lq6gsi1ax7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend detection: last 5 games vs prior 5 using ROW_NUMBER + conditional aggregation\n",
    "trend_query = f\"\"\"\n",
    "WITH game_numbered AS (\n",
    "  SELECT\n",
    "    player_id,\n",
    "    player_name,\n",
    "    pts, reb, ast,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY player_id ORDER BY game_date DESC\n",
    "    ) AS game_num\n",
    "  FROM `{GAME_LOGS_TABLE}`\n",
    "),\n",
    "splits AS (\n",
    "  SELECT\n",
    "    player_name,\n",
    "    COUNT(CASE WHEN game_num <= 5 THEN 1 END) AS recent_gp,\n",
    "    COUNT(CASE WHEN game_num BETWEEN 6 AND 10 THEN 1 END) AS prior_gp,\n",
    "    ROUND(AVG(CASE WHEN game_num <= 5 THEN pts END), 1) AS recent_ppg,\n",
    "    ROUND(AVG(CASE WHEN game_num BETWEEN 6 AND 10 THEN pts END), 1) AS prior_ppg,\n",
    "    ROUND(AVG(CASE WHEN game_num <= 5 THEN reb END), 1) AS recent_rpg,\n",
    "    ROUND(AVG(CASE WHEN game_num BETWEEN 6 AND 10 THEN reb END), 1) AS prior_rpg,\n",
    "    ROUND(AVG(CASE WHEN game_num <= 5 THEN ast END), 1) AS recent_apg,\n",
    "    ROUND(AVG(CASE WHEN game_num BETWEEN 6 AND 10 THEN ast END), 1) AS prior_apg\n",
    "  FROM game_numbered\n",
    "  WHERE game_num <= 10\n",
    "  GROUP BY player_id, player_name\n",
    "  HAVING recent_gp >= 3 AND prior_gp >= 3\n",
    ")\n",
    "SELECT\n",
    "  player_name,\n",
    "  recent_gp,\n",
    "  prior_gp,\n",
    "  recent_ppg,\n",
    "  prior_ppg,\n",
    "  ROUND(recent_ppg - prior_ppg, 1) AS pts_delta,\n",
    "  recent_rpg,\n",
    "  prior_rpg,\n",
    "  ROUND(recent_rpg - prior_rpg, 1) AS reb_delta,\n",
    "  recent_apg,\n",
    "  prior_apg,\n",
    "  ROUND(recent_apg - prior_apg, 1) AS ast_delta\n",
    "FROM splits\n",
    "ORDER BY pts_delta DESC\n",
    "\"\"\"\n",
    "\n",
    "bq_trends = bq_client.query(trend_query).to_dataframe()\n",
    "print(\"=== Trend Detection (BigQuery: last 5 games vs prior 5) ===\")\n",
    "bq_trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bbe908",
   "metadata": {},
   "source": [
    "## 6. Automated Recent Trend Detection\n",
    "\n",
    "Automatically identify the most recent statistically meaningful player trend by comparing recent performance vs the prior window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3020a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TREND_WINDOW_DAYS = int(os.getenv(\"TREND_WINDOW_DAYS\", \"7\"))\n",
    "TREND_MIN_GAMES = int(os.getenv(\"TREND_MIN_GAMES\", \"2\"))\n",
    "\n",
    "\n",
    "def detect_recent_trend(df: pd.DataFrame, window_days: int = TREND_WINDOW_DAYS, min_games: int = TREND_MIN_GAMES):\n",
    "    \"\"\"Return top recent player trends by stat change across two adjacent windows.\"\"\"\n",
    "    required = {\"GAME_DATE\", \"PLAYER_ID\", \"PLAYER_NAME\", \"PTS\", \"REB\", \"AST\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns for trend detection: {sorted(missing)}\")\n",
    "\n",
    "    working = df.copy()\n",
    "    working[\"GAME_DATE\"] = pd.to_datetime(working[\"GAME_DATE\"], errors=\"coerce\")\n",
    "    working = working.dropna(subset=[\"GAME_DATE\"]).copy()\n",
    "\n",
    "    latest_date = working[\"GAME_DATE\"].max().normalize()\n",
    "    recent_start = latest_date - timedelta(days=window_days - 1)\n",
    "    prior_start = recent_start - timedelta(days=window_days)\n",
    "    prior_end = recent_start - timedelta(days=1)\n",
    "\n",
    "    recent = working[(working[\"GAME_DATE\"] >= recent_start) & (working[\"GAME_DATE\"] <= latest_date)]\n",
    "    prior = working[(working[\"GAME_DATE\"] >= prior_start) & (working[\"GAME_DATE\"] <= prior_end)]\n",
    "\n",
    "    stat_cols = [\"PTS\", \"REB\", \"AST\"]\n",
    "\n",
    "    recent_agg = (\n",
    "        recent.groupby([\"PLAYER_ID\", \"PLAYER_NAME\"], as_index=False)\n",
    "        .agg({**{c: \"mean\" for c in stat_cols}, \"GAME_DATE\": \"count\"})\n",
    "        .rename(columns={\"GAME_DATE\": \"recent_games\", **{c: f\"recent_{c}\" for c in stat_cols}})\n",
    "    )\n",
    "    prior_agg = (\n",
    "        prior.groupby([\"PLAYER_ID\", \"PLAYER_NAME\"], as_index=False)\n",
    "        .agg({**{c: \"mean\" for c in stat_cols}, \"GAME_DATE\": \"count\"})\n",
    "        .rename(columns={\"GAME_DATE\": \"prior_games\", **{c: f\"prior_{c}\" for c in stat_cols}})\n",
    "    )\n",
    "\n",
    "    merged = recent_agg.merge(prior_agg, on=[\"PLAYER_ID\", \"PLAYER_NAME\"], how=\"inner\")\n",
    "    merged = merged[(merged[\"recent_games\"] >= min_games) & (merged[\"prior_games\"] >= min_games)].copy()\n",
    "\n",
    "    if merged.empty:\n",
    "        return pd.DataFrame(), \"No trend detected: insufficient overlapping games in recent and prior windows.\"\n",
    "\n",
    "    long_rows = []\n",
    "    for stat in stat_cols:\n",
    "        tmp = merged[[\"PLAYER_ID\", \"PLAYER_NAME\", \"recent_games\", \"prior_games\", f\"recent_{stat}\", f\"prior_{stat}\"]].copy()\n",
    "        tmp = tmp.rename(columns={f\"recent_{stat}\": \"recent_avg\", f\"prior_{stat}\": \"prior_avg\"})\n",
    "        tmp[\"stat\"] = stat\n",
    "        tmp[\"delta\"] = (tmp[\"recent_avg\"] - tmp[\"prior_avg\"]).round(2)\n",
    "        tmp[\"pct_change\"] = ((tmp[\"delta\"] / tmp[\"prior_avg\"].replace(0, pd.NA)) * 100).round(1)\n",
    "        long_rows.append(tmp)\n",
    "\n",
    "    trends = pd.concat(long_rows, ignore_index=True)\n",
    "    trends = trends.sort_values([\"delta\", \"recent_avg\"], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "    top = trends.iloc[0]\n",
    "    summary = (\n",
    "        f\"Top recent trend through {latest_date.date()}: {top['PLAYER_NAME']} increased {top['stat']} by \"\n",
    "        f\"{top['delta']} (from {top['prior_avg']:.1f} to {top['recent_avg']:.1f}) \"\n",
    "        f\"over the last {window_days} days vs the previous {window_days} days.\"\n",
    "    )\n",
    "\n",
    "    return trends, summary\n",
    "\n",
    "\n",
    "trend_candidates, trend_summary = detect_recent_trend(all_game_logs)\n",
    "print(\"=== AUTOMATED RECENT TREND HIGHLIGHT ===\")\n",
    "print(trend_summary)\n",
    "print(\"\\n=== TOP 10 TREND CANDIDATES ===\")\n",
    "display(trend_candidates.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loqw020l5v",
   "metadata": {},
   "source": [
    "## 7. AI-Powered Analysis Article\n",
    "\n",
    "Use Claude API to synthesize leaderboard data, season averages, and player trends into a full analysis article with actionable insights and a TLDR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d51905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize Claude client (uses ANTHROPIC_API_KEY environment variable)\n",
    "ant_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "claude_client = anthropic.Anthropic(api_key=ant_api_key) if ant_api_key else None\n",
    "ANTHROPIC_MODEL = os.getenv(\"ANTHROPIC_MODEL\", \"claude-sonnet-4-5-20250929\")\n",
    "\n",
    "OUTPUT_DIR = Path(os.getenv(\"NBA_OUTPUT_DIR\", \"reports\"))\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def generate_analysis_article(\n",
    "    daily_leaders: pd.DataFrame,\n",
    "    season_averages: pd.DataFrame,\n",
    "    trends: pd.DataFrame,\n",
    "    trend_highlight: str = \"\",\n",
    "    season: str = SEASON,\n",
    ") -> str:\n",
    "    \"\"\"Generate a blog-style NBA analysis article from leaderboard and trend data.\"\"\"\n",
    "    if claude_client is None:\n",
    "        return \"Skipping AI analysis: ANTHROPIC_API_KEY is not set.\"\n",
    "    if daily_leaders.empty and season_averages.empty and trends.empty:\n",
    "        return \"Skipping AI analysis: no data available.\"\n",
    "\n",
    "    leaders_preview = daily_leaders.head(15).to_string(index=False) if not daily_leaders.empty else \"N/A\"\n",
    "    season_preview = season_averages.head(15).to_string(index=False) if not season_averages.empty else \"N/A\"\n",
    "    trends_preview = trends.head(10).to_string(index=False) if not trends.empty else \"N/A\"\n",
    "    today = pd.Timestamp.utcnow().strftime(\"%B %d, %Y\")\n",
    "\n",
    "    message = claude_client.messages.create(\n",
    "        model=ANTHROPIC_MODEL,\n",
    "        max_tokens=2500,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"You are an NBA beat writer for a popular sports blog. Write an engaging,\n",
    "editorial-style article that reads like something you'd find on The Ringer or ESPN.\n",
    "Use ONLY the data below. Do not invent stats or reference players not in the data.\n",
    "\n",
    "--- DAILY LEADERBOARD (recent game-day leaders for PTS, REB, AST) ---\n",
    "{leaders_preview}\n",
    "\n",
    "--- SEASON AVERAGES (per-game stats, minimum 5 games played) ---\n",
    "{season_preview}\n",
    "\n",
    "--- PLAYER TRENDS (last 5 games vs prior 5 games, delta = recent minus prior) ---\n",
    "{trends_preview}\n",
    "\n",
    "Trend highlight from automated detection:\n",
    "{trend_highlight}\n",
    "\n",
    "Today's date: {today}\n",
    "Season: {season}\n",
    "\n",
    "Write a blog article (strictly 400-500 words, do NOT exceed 500 words) with this structure:\n",
    "\n",
    "1. A compelling headline\n",
    "\n",
    "2. A bold TLDR at the top (2-3 sentences, italicized) that hooks the reader with the\n",
    "   single biggest storyline from the data.\n",
    "\n",
    "3. A narrative opening paragraph that sets the scene. Don't list stats yet — tell the\n",
    "   reader what the story is. What's the headline? Who should they be paying attention to?\n",
    "\n",
    "4. A \"Who's Running the Show\" section written in flowing paragraphs (NOT bullet points).\n",
    "   Weave together the leaderboard dominance and season averages into a narrative. Compare\n",
    "   players, describe what makes their recent stretch impressive, and reference specific\n",
    "   game dates and stat lines from the leaderboard data.\n",
    "\n",
    "5. A \"The Hot Hand\" section (also flowing prose, NOT bullets) covering players trending\n",
    "   up. Describe the shift in their game — what changed in the last 5 games vs the prior\n",
    "   5? Use the delta numbers naturally in sentences, not as a list.\n",
    "\n",
    "6. A \"Cooling Off\" section (prose) for players trending down. Frame it as a narrative —\n",
    "   is it a slump, a role change, fatigue? Use the delta numbers in context.\n",
    "\n",
    "7. A \"What to Watch\" closing section with 2-3 forward-looking storylines written as\n",
    "   short editorial paragraphs. Frame these as questions or scenarios that fans should\n",
    "   track. End with a sentence that leaves the reader wanting to check back.\n",
    "\n",
    "Style rules:\n",
    "- Write like a journalist, not a data analyst. Stats support the story, not the other way around.\n",
    "- Use transitions between sections. The article should flow, not feel like five disconnected blocks.\n",
    "- Vary sentence length. Mix short punchy lines with longer analytical ones.\n",
    "- No bullet points or numbered lists anywhere in the article.\n",
    "- Reference specific game dates and matchups from the leaderboard when possible.\n",
    "- Every stat claim must come from the provided data.\n",
    "- IMPORTANT: Keep it tight. 400-500 words total. Be concise and selective with stats.\"\"\",\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return message.content[0].text\n",
    "\n",
    "\n",
    "# Generate the analysis article from BigQuery results\n",
    "article = generate_analysis_article(\n",
    "    daily_leaders=results,\n",
    "    season_averages=season_avg_df,\n",
    "    trends=bq_trends,\n",
    "    trend_highlight=trend_summary,\n",
    ")\n",
    "\n",
    "# Save article to text file with run date in filename\n",
    "run_date = pd.Timestamp.utcnow().strftime(\"%Y-%m-%d\")\n",
    "output_file = OUTPUT_DIR / f\"nba_analysis_{run_date}.txt\"\n",
    "output_file.write_text(article, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Article saved to: {output_file}\")\n",
    "print(f\"{'=' * 60}\\n\")\n",
    "print(article)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
